1:Broker 副本基本信息
    1.Kafka 副本作用: 提高数据可靠性
    2.Kafka 默认副本1个,生产环境一般配置为2个,保证数据可靠性,太多副本会增加磁盘存储空间,
      增加网络上数据传输,降低效率
    3.Kafka 中副本分为: Leader 和 Follwer. Kafka 生产者只会把数据发往 Leader,
      然后 Follower 找 Leader 进行同步数据
    4.Kafka 分区中的所有副本统称为 AR (Assigned Replicas)
      AR = ISR + OSR
    5.ISR:表示和 Leader 保持同步的 Follower 集合. 如果 Follower 长时间未向 Leader 发送
      通信请求或同步数据,则该 Follower 将被提出 ISR. 该时间阀值由 replica.lag.time.max.ms
      参数设定,默认30s. Leader 发生故障之后,就会从 ISR 中选举新的 Leader
      OSR: 表示 Follower 与 Leader 副本同步时, 延迟过多的副本.


2:Follower 故障处理
    LEO(Log End Offset): 每个副本的最后一个 offset, LEO 其实是最新的 offset+1
    HW(High Watermark): 所有副本中最小的 LEO

    1.Follower 发生故障后会被临时踢掉
    2.这个期间 Leader 和 Follower 继续接收数据
    3.待该 Follower 恢复后, Follower 会读取本地磁盘记录的上次的 HW, 并将 log 文件高于
      HW的部分截掉, 从 HW 开始向 Leader 进行同步
    4.等待 Follower 的 LEO 大于等于该 partition 的 HW, 即 Follower 追上 Leader 之后,
      就可以重新加入 ISR 了.

3.Leader 故障处理
    1.Leader 发生故障之后,会从 ISR 中选出一个新的 Leader
    2.为了保证多个副本之间的数据一致性,其余的 Follower 会先将各自的 log 文件高于 HW 的部分
      截掉,然后从新的 Leader 同步数据.
    Note: 这只能保证副本之间的数据一致性,并不能保证数据不丢失或者不重复.


4.分区副本分配
5.生产经验 -- 手动调整分区副本存储
    - kafka 只会根据自己的代码规则创建对应的分区副本,就会导致个别服务器存储压力很大.
      所以需要手动调整分区副本的存储
    - 创建一个新的 topic, 4个分区,两个副本,名称为 three, 将该 topic 的所有副本都存储到
      broker0 和 broker1 两台服务器上.
    kafka-topics.sh --bootstrap-server kafka01:9092 --topic three --create --partitions 4 --replication-factor 2
        # 创建 topic
    kafka-reassign-partitions.sh --bootstrap-server kafka01:9092 --reassignment-json-file manually-adjust-partitions-replication-factor.json --execute
        # 执行副本存储计划
    kafka-reassign-partitions.sh --bootstrap-server kafka01:9092 --reassignment-json-file manually-adjust-partitions-replication-factor.json --verify
        # 验证副本存储计划
    kafka-topics.sh --bootstrap-server kafka01:9092 --topic three --describe


6.Leader Partition 自动平衡
    - 正常情况下, Kafka 自动把 Leader Partition 均匀的分散在各个机器上,来保证每个机器的
      读写吞吐量都是均匀的. 但是如果某些 broker 宕机,会导致 Leader Partition 过于集中在
      某些少部分几台 Broker 上. 这会导致少数几台 broker 的读写压力过高,其他宕机的 broker
      重启之后都是 follower partition, 读写请求很低,造成集群负载不均衡
    - auto.leader.rebalance.enable, 默认是 true, 自动 Leader Partition 平衡
    - leader.imbalance.per.broker.percentage 默认是 10%, 么个 broker 允许的不平衡的 leader
      的比率. 如果每个 broker 超过了这个值,控制器会触发 leader 的平衡.
    - leader.imbalance.check.interval.seconds
      默认值 300 秒. 检查 leader 负载是否平衡的间隔时间.
    - 假设一个 topic 有4个分区和4个副本
      如果 broker0 节点, 分区2的 AR 优先级副本是0节点,但是0节点却不是 Leader 节点,所以不平衡
      数增加1, AR 副本数为4, 所以 broker0 节点的不平衡率为 1/4 > 10%, 需要再平衡
    - broker2 和 broker3 节点和 broker0 不平衡率一样,需要再平衡. broker1 的不平衡数为0,
      不需要再平衡.
    - 生产环境不建议将自动平衡设置为 true, 或者自动平衡的触发比例调大一些, 比如 30%
      原则上就是不要频繁的触发再平衡操作, 浪费大量的性能.


7.增加副本因子
    // 无法直接通过 kafka-topics.sh --alter 来直接修改副本因子
    kafka-reassign-partitions.sh --bootstrap-server kafka01:9092 --reassignment-json-file increase-replication-factor.json --execute
    kafka-reassign-partitions.sh --bootstrap-server kafka01:9092 --reassignment-json-file increase-replication-factor.json --verify
    kafka-topics.sh --bootstrap-server kafka01:9092 --topic four --describe


8.Kafka 文件存储机制
    - Topic 是逻辑上的概念, 而 Partition 是物理上的概念, 每个 partition 对应于一个 log 文件.
      该 Log 文件中存储的就是 Producer 生产的数据, Producer 产生的数据会被不断追加到该 Log
      文件末端, 以防止 log 文件过大导致数据定位效率低下, kafka 采取了分片和索引机制,将每个
      partition 分为多个 segment. 每个 segment 包括: .index 文件 .log 文件 和 .timeindex
      等文件. 这些文件位于一个文件夹下,该文件夹的命名规则为: topic 名称 + 分区序号, 例如 first-0
    - .log 日志文件
      .index 偏移量索引文件
      .timeindex 时间戳索引文件
      其他文件
    - index 和 log 文件以当前 segment 的第一条消息的 offset 命名.
    - index 为稀疏索引, 大约每往 log 文件写入 4kb 数据, 会往 index 文件写入一条索引,
      参数 log.index.interval.bytes 默认 4kb
    - index 文件中保存的 offset 为相对 offset, 这样能确保 offset 的值所占空间不会过大,
      因此能将 offset 的值控制在固定大小.

9.文件清除策略
    1:Kafka 中默认的日志保留时间为7天,可以通过调整如下参数修改
        log.retention.hours                 最低优先级,默认7天
        log.retention.minutes               分钟
        log.retention.ms                    最高优先级毫秒
        log.retention.check.interval.ms     负责设置检查周期,默认5分钟.
    2.kafka 提供的日志清理策略有 delete 和 compact 两种
    3.delete 策略, 将过期数据删除
        log.cleanup.policy = delete  所有的数据启用删除策略
        - 基于时间: 默认打开. 以 segment 中所有记录中最大时间戳作为该文件的时间戳.
        - 基于大小: 默认关闭. 超过设置的所有日志大小, 删除最早的 segment
          log.retention.bytes 默认等于 -1, 表示无穷大
    4.compact 策略, 对于相同的 key 的不同 value 值,只保留最后一个版本
        - log.cleanup.policy = compact  所有数据启用压缩策略
        - 压缩后的 offset 可能是不连续的,当从这些 offset 消费消息时,将会拿到比这个 offset
          大的 offset 对应的消息.


10.高效读写数据
    1.Kafka 本身就是分布式集群,可以采用分区技术,并行度高
    2.读数据采用稀疏索引,可以快速定位要消费的数据
    3.顺序写磁盘
    4.页缓存 + 零拷贝技术
      零拷贝: kafka 的数据加工处理操作交由 Kafka 生产者和 Kafka 消费者处理.
      Kafka Broker 底层不关心存储的数据,所以就不用走应用层,传输效率高.
      PageCache 页缓存: kafka 重度依赖底层操作系统提供的 PageCache 功能. 当上层有写操作时,
      操作系统只是将数据写入 PageCache. 当读操作发生时,先从 PageCache 中查找,如果找不到,
      再从磁盘读取. 实际上 PageCache 是把尽可能多的空闲内存都当作了磁盘缓存来使用
